//SERVICE - IA
import { streamText } from 'ai'
import { openrouter } from '../lib/ai'

/*
https://ai-sdk.dev/docs/
https://ai-sdk.dev/docs/foundations/prompts#system-prompts

'ai' es el Vercel AI SDK.
Es una librerÃ­a creada por el equipo de Vercel para facilitar la integraciÃ³n de 
modelos de lenguaje (LLMs - Large Language Models) como OpenAI, OpenRouter y otros, 
dentro de aplicaciones web modernas (especialmente en Next.js 14+).

ğŸ“Œ Â¿Para quÃ© sirve?
    -Enviar mensajes a modelos LLM desde frontend (React) con hooks como useChat o 
    useCompletion.
    -Recibir respuestas en streaming desde el backend.
    -Manejar el estado de una conversaciÃ³n (historial de mensajes, estado de carga, errores) 
    sin tener que programarlo manualmente.
    -Simplificar la comunicaciÃ³n entre el cliente y la API que llama al modelo.

ğŸ“Œ RelaciÃ³n con @openrouter/ai-sdk-provider
    -El paquete ai te da los hooks y utilidades generales.
    -@openrouter/ai-sdk-provider te da la funciÃ³n de stream para conectar 
    con OpenRouter especÃ­ficamente.

    Paquete	                        PropÃ³sito
    -ai	                            Hooks y utilidades del Vercel AI SDK. Maneja frontend y backend de IA.
    -@openrouter/ai-sdk-provider	Adaptador de stream para conectar OpenRouter AI con ai.
*/

/*
ğŸ“Œ streamText
streamText es una funciÃ³n del AI SDK que permite enviar un prompt de texto a un modelo LLM y 
obtener la respuesta en streaming.
    ğŸ‘‰ EstÃ¡ pensado para text completions tradicionales (prompt â†’ respuesta)
    ğŸ‘‰ No para chats de mensajes mÃºltiples (para eso es useChat y chat.completions.create).

    const { textStream } = await streamText({
        model,
        prompt,
        system,
        maxTokens
        temperature,
        // otros parÃ¡metros
    });

-model â†’ puede ser una string (ej: "openai/gpt-4o") o una funciÃ³n que devuelve un modelo preconfigurada 
que, cuando se utiliza en una funciÃ³n como streamText, ya lleva implÃ­cita la API Key. En este caso 
se configuro previamente con createOpenRouter.
-prompt â†’ string que quieres completar.
-temperature â†’ 	(opcional) Creatividad (0-2)
-system â†’ (opcional )conjunto inicial de instrucciones que se dan a los modelos y que ayudan a guiar 
y limitar sus comportamientos y respuestas.

ğŸ“Œ result.textStream 
Se estÃ¡ regresando solo la propiedad textStream, que es un AsyncIterableStream<string> que es un objeto 
que permite leer datos secuenciales a medida que llegan, sin esperar a que toda la respuesta estÃ© completa.
Ideal para streaming en tiempo real, como cuando quieres que el frontend vaya mostrando letra por letra 
o bloque por bloque mientras el modelo genera contenido.
*/
export const generateRecipe = async (prompt : string) => {
    const result = streamText({
        model: openrouter('google/gemini-2.5-flash-lite-preview-06-17'),
        prompt,
        temperature: 1,
        system: 'Eres un bartender profesional que puede explicar la preparaciÃ³n de diferentes cÃ³cteles a cualquier persona'
    });

    return result.textStream 
}